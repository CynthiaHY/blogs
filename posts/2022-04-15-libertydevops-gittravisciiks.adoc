---
layout: post
title: "Continuous integration and delivery (CI/CD) of Open Liberty applications to OpenShift using Travis CI"
categories: blog
author_picture: https://avatars3.githubusercontent.com/shamjithantholi
author_github: https://github.com/shamjithantholi
seo-title: TITLE - OpenLiberty.io
seo-description: DESCRIPTION
blog_description: "A high level explanation about how to build a devops pipeline with Travis CI. "
open-graph-image: https://openliberty.io/img/twitter_card.jpg
---
= Continuous integration and delivery (CI/CD) of Open Liberty applications to OpenShift using Travis CI
Shamjith Antholi https://github.com/shamjithantholi
:imagesdir: /
:url-prefix:
:url-about: /

[#Intro]
== What is DevOps
DevOps is a culture or a process, which enables the integration of the software development (dev) and IT operations (ops). It can facilitate the setup of deployment pipeline and helps to improve the speed of software delivery. Automation of the entire build, test, and deployment of the software applications can be achieved through DevOps process. There are tons of efficient applications and process methodologies available in the market that can be readily integrated to the DevOps pipeline, which can help to achieve the wanted results.

== CI/CD and Travis CI
CI/CD are acronym’s for continuous integration, and continuous delivery or deployment used in DevOps. Continuous integration is a process where developers frequently merge code changes into a source code repository, which automatically start code build, security scan, and test execution and deployment. Automation of this process enables organizations to release on a more frequent basis without compromising on quality.

Travis CI is a contienous integration service use to build and test the code. Travis CI works with various Git flavors ( eg: GitHub, Bitbucket).

OpenShift is a containerization platform from RedHat. Contiainer orchastration in OpenShift are managed by Kubernetes and its build around linux containers.

Open Liberty is a lightweight Java runtime for building cloud-native applications and microservices. In this blog, it details how you can use Jenkins in CI/CD pipeline for Java based Openliberty application build/test/deployment Openliberty link:https://openliberty.io[OpenLiberty] .

== Getting ready
Below given is a generic architecture of a simple one dimensional devops pipeline (single environment view).

image::/img/blog/liberty-devops-generic-architecture.png[Liberty devops generic architecture diagram ,width=70%,align="center"]

In this blog i will give you a high level overview of using travis CI as a "code build tool" (with sample codes and required explanations), how you can setup Projects on OpenShift, how you can connect with OpenShift and perform the application deployment, docker registry concepts, security scanning, unit and functional testing with Travis etc. Detailed explanation of technologies used in this blog, tool installation, complex devops pipeline design details of multi-environment application deployment are not in the scope of this blog. 

Basic understanding of git, Docker and containerization concepts are a prerequisite for this blog.

The standard Dockerfile which you use in general will not be enough to do the Liberty application deployment on containerized environment, a sample OpenLiberty compliant Dockerfile snipped in given below, please configure it as per your requirement

  FROM icr.io/appcafe/open-liberty:kernel-slim-java8-openj9-ubi
  # Add Liberty server configuration including all necessary features
COPY --chown=1001:0  server.xml /config/
# Modify feature repository (optional)
# A sample is in the 'Getting Required Features' section below
COPY --chown=1001:0 featureUtility.properties /opt/ol/wlp/etc/
# This script will add the requested XML snippets to enable Liberty features and grow image to be fit-for-purpose using featureUtility. 
# Only available in 'kernel-slim'. The 'full' tag already includes all features for convenience.
RUN features.sh
# Add interim fixes (optional)
#COPY --chown=1001:0  interim-fixes /opt/ol/fixes/
.
.
.
.
RUN cp <open-liberty-application>.war /config/dropins/
RUN chmod 755 /config/dropins/<open-liberty-application>.war
RUN chown 1001:0 /config/dropins/<open-liberty-application>.war
WORKDIR /
# This script will add the requested server configurations, apply any interim fixes and populate caches to optimize runtime
RUN configure.sh


=== Travis CI setup ===

Provision *Travis CI* from link:https://www.travis-ci.com/?_gl=1%2A1tiil9q%2A_ga%2AMTIwMjg2NTQ2NS4xNjUwNTUwODU5%2A_ga_XRYGSZFQ0P%2AMTY1MDkwOTQwMC40LjAuMTY1MDkwOTQwOC41Mg..[Travis CI] and integrate your GitHub repository with it (when your personal profile or repository is integrated with travis CI, presense of a *.travis.yml* file in the repository will be enough for syncing that repository with travis CI). 

     --> Go to "https://app.travis-ci.com/signin" and Sign up with GitHub.
     --> Accept the Authorization of Travis CI. You’ll be redirected to GitHub.

image::/img/blog/travisci-homepage.png[Travis CI - Github integration ,width=50%,align="center"]

image::/img/blog/travis-integrated-gitrepo.png[Travis CI - Github integration ,width=50%,align="center"]

     --> Activate the required project as shown in the above screenshot

*Additional tools*

Basic additional tools required on CI/CD pipeline apart from Jenkins are 

* A source code management (SCM) tool like GitHub.

     Provision a public or private github repository (github.com) and checkin your code into it. 
     Create any branching strategy of your choice (example: develop --> qa --> develop branch hierarchy). More details about branch are available here "https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow" 

* Vulnerability scanning tools, like Aqua, Trivy, NexusIQ, Sonarqube (optional)

      Vulnerability scan will discover the critical issues in the source code and the open source jar files used 
      in the application. 
      Vulnerability scan can be done on multiple phases, either using CLI commands in Travis CI along with the application 
      code build commands or by manually uploading all the jars to the 
      scanning software or by scanning the docker image created for deployment. 
      Most of the scanning softwares do have a recommendation section which we can use to select the correct jar (please 
      verify the database against which those applications are comparing the vulnerability score and take the best decision for your application). 
      Static code analysis can be done based on the code rules made available by the scanning product or you can develop 
      your own custom rules against which you can scan your code before production deployment to find out any critical faults. 
      Softwares like Aqua (docker image scan - "https://www.aquasec.com") and Aqua trivy ("https://www.aquasec.com/products/trivy/"), SonarQube (static code analysis - "https://www.sonarqube.org"), NexusIQ (jar scan - "https://help.sonatype.com/iqserver") are popular in market for this. 
      More details are given in the below sections.

* OpenShift container platform 

     I am using OpenShift (https://www.redhat.com/en/technologies/cloud-computing/openshift) for this blog. Provision the OpenShift  
     cluster on IBM cloud (https://cloud.ibm.com), generate OpenShift token for CLI connectivity, verify the basic 
     k8s cluster login commands to various clusters or namespaces (like dev cluster, qa cluster etc). 
     You can use any other kubernetes service of your choice.     

* Logging and monitoring

     Since the cloud application usage are charged based on time used, it's very important to design the use of cloud 
     resources in an efficient way. Memory usage stats and application storage plan is important in this perspective 
     because the choice of memory/CPU numbers can be set based on this stats, also choice of storage devices and 
     its amount allocation also can be selected based on these data.
     Also, OpenShift/kubernetes does not store any logs or memory stats permanently. There are applications like dynatrace and 
     grafana available in market for storing memory stats permanently and applications like prometheus and splunk in 
     market for storing application and cluster log permanently. 
     More details about the tools and k8s commands are given in below sections
    

== OpenShift project setup and manual deployment

The first step is to complete the openshift platform setup to make it ready for application deployment. After installing/provisioning a managed OpenShift, login to it using username and password and get the authentication token which is going to be used in Travis CI for connectivity

image::/img/blog/openshift-cli-tools.png[OpenShift CLI tools ,width=70%,align="center"]

Unzip the downloaded OCP cli and upload the same to your GitHub repository. 

Login to OpenShift from CLI and create a new project/namespace and change to that namespace.

image::/img/blog/ocp-login.png[OpenShift login details ,width=70%,align="center"]

Create an OpenShift secret to checkout the code from GitHub to OpenShift (upload the public to github )
     
        oc create secret generic ssh-git \
              --from-file=ssh-privatekey=/Users/<username>/.ssh/id_rsa \
              --type=kubernetes.io/ssh-auth           

Create a new application on OpenShift

        oc new-app git@github.ibm.com:shamjith-antholi/traviscidemo.git --source-secret=<ssh-git>

This command will create the uild, deployment, service and routes on OpenShift. When the build is completed, docker image will be stored in the OpenShift internal image stream. Configure the OpenShift build to start the deployment automatically after a successfull deployment (generally this option is enable by default). Verify that this application is deployed properly on OpenShift and endpoints are reachable before moving ahead to automate the deployment process using Travis CI.

------- copy paste some openshift UI pics of deployment/service/route etc-----------

== Automating application deployment on OpenShift using Travis CI

As explained earlier, *.travis.yml* file must be available on the base path of the GitHub repository. An example view of Github repository base path is given below

      ------ Git repo base path screenshot ------------

Travis CI provides wide variety of configuration options, but i will be providing a simple workable confirguration sample code which is good enough to automate 



== Building the Liberty Java code, packaging and generating Docker image

Below given sample pipeline code can perform the code build, packaging and generating docker image and pushing the same to remote docker hub. You can use it by modifying the parameter section (<>)

 pipeline {
     agent any
     stages {
       stage('Build') {
           steps {
                checkout([$class: 'GitSCM', branches: [[name: '*/main']], extensions: [], userRemoteConfigs: [[credentialsId: ‘<git token>, url: 'https://github.com/liberty/app.git']]])

                    sh '''
                            mvn -U package
                            docker login <remote-docker-image-repository-url> -u "${USERNAME}" -p “${PASSWORD}”
            docker tag liberty-$<code identifier>:$<docker image version> <remote-docker-image-repository-url>/<docker-repo-name>/liberty-$<code identifier>:$<docker image version>
            docker push <remote-docker-image-repository-url>/<docker-repo-name>/liberty-$<code identifier>:$<docker image version>

                    '''   
                   }}}}


Following are the parameter used in this example code

* git token: Personal access token generated from github.
* remote-docker-image-repository-url : Docker hub repository url.
* USERNAME/PASSWWORD: user name and password to connect to docker registry.

image::/img/blog/jenkins-cred-binding-and-corresponding-param.png[Pipeline credential binding and corresponding param,width=30%,align="center"]

* code identifier: This is optional, a unique docker image identifier
* docker image version: docker image version number, a unique identifier   

*Security scan* Security scan can be done along with maven build command (CLI commands way of application scanning) or can do it in a separate pipeline stage. 

For static code analysis, we can use SonarQube community edition. Install sonarqube server by either using file startup type from cli downloading the package in link:https://www.sonarqube.org/success-download-community-edition/[SonarQube server install package] or use docker way as explained in link:https://docs.sonarqube.org/latest/setup/get-started-2-minutes/[Sonarqube server install steps]. SonarQube jenkins client setup details are given in this page link:https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/[SonarQube client for jenkins]. 

For Docker image scan, you can use link:https://hub.docker.com/r/aquasec/trivy/[Docker image scan with trivy]. This scan will provide the vulnerability details of open source jars used in the application.Sample commands are given below

       sh '''
             docker login -u $docker_login -p $docker_password
             docker build -t $docker_login/sampleapp:v1.0 .
             docker push $docker_login/sampleapp:v1.0 
             docker run aquasec/trivy image $docker_login/sampleapp:v1.0
       '''



== Deployment (CLI) 

For simplicity, I will use the command line (CLI) option to configure Jenkins to deploy a Liberty application to Kubernetes. You could use one of many tools though, such as Helm, Travis CI, Circle CI, etc.

Create a new stage in the pipeline code and write all the required commands between the shell option (sample commands give below)
                           
                           sh '''
                              ibmcloud ks cluster config --cluster $CLUSTER-ID
                              kubectl config current-context
                              kubectl create -f deploy/deployment.yaml #( simple k8s deployment command )
                              kubectl create -f deploy/service.yaml #( simple k8s deployment command )
                              kubectl create -f deploy/route.yaml #( simple k8s deployment command )
                              '''

Maintain all the kubernetes configuration files in the same code repository (under a folder called "deploy") 

When Jenkins has checked out the Liberty Java application code for the code build, all the Kubernetes configuration files are also downloaded to the Jenkins workspace so that Jenkins can run the IBM Cloud and Kubernetes commands to connect to the Kubernetes cluster and deploy the application.

 -> Set the kubernetes context as per the requirement, for example, if we need to deploy into development cluster, 
 then the context should be set to development cluster, for deployment into QA environment, 
 set it into QA context ( this context setting is depending on the design of the cluster)

All the other required application deployment commands are available in this kubernetes command page which is very straightforward
link:https://kubernetes.io/docs/reference/kubectl/cheatsheet/[Kubernetes sample commands] 

== QA testing options
Apart from running JUnit test cases along with the code build phase, Jenkins can trigger functional and integration QA test cases automatically after deploying the Liberty application.

Configure the test cases on jenkins job and test it manually. Create an "Authentication Token" in "Trigger builds remotely" section under "Build Triggers". Trigger this test case from docker "entrypoint" file using remote rest api call using this authentication token as the identifier

Eg: curl -I -u <auth-token> https://<jenkins-host>/job/<job-name>/build?token=<authentication-token>
Note: Auth token can be generated from postman

== Kubernetes monitoring tools

Kubernetes provides commands to check the application/cluster logs and memory/cpu usage through the commands like 

    -> kubectl logs ..
    -> cat /sys/fs/cgroup/cpu/cpuacct.usage (after connecting to k8s pod)
    -> cat /sys/fs/cgroup/memory/memory.usage_in_bytes (after connecting to k8s pod)

For persistence of logs and usage stats, there are sevaral applications available in the market which can be integrated with kubernetes, details about some of those apps are given below

These tools are deployed in kubernetes cluster itself where the application is running and exposed using route and access the gathered details from UI.

    -> https://grafana.com/oss/loki/
    -> https://medium.com/nerd-for-tech/logging-at-scale-in-kubernetes-using-grafana-loki-3bb2eb0c0872
    -> https://prometheus.io
    -> https://k21academy.com/docker-kubernetes/prometheus-grafana-monitoring/



== Conclusion
There are many ways in which you can configure your DevOps pipeline. This blog post is a quick introduction to how you can use Jenkins to set up a simple CI/CD pipeline to build and deploy your Liberty Java applications.
