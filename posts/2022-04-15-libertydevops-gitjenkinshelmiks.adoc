---
layout: post
title: "Using Jenkins for CI/CD with Liberty"
categories: blog
author_picture: https://avatars3.githubusercontent.com/shamjithantholi
author_github: https://github.com/shamjithantholi
seo-title: TITLE - OpenLiberty.io
seo-description: DESCRIPTION
blog_description: "A high level explanation about how to build a devops pipeline with Jenkins as the core controller component "
open-graph-image: https://openliberty.io/img/twitter_card.jpg
---
= Using Jenkins for CI/CD with Liberty
Shamjith Antholi https://github.com/shamjithantholi
:imagesdir: /
:url-prefix:
:url-about: /

[#Intro]
== What is DevOps
DevOps is a culture or a process which enables the integration of the software development (dev) and IT operations (ops) which will facilitate the setup of deployment pipeline as well as helps to improve the speed of software delivery. Automation of the entire build, test and deployment of the software applications can be achieved through DevOps process. There are tons of efficient applications and process methodologies available in the market which can be readily integrated to the DevOps pipeline which will help to achieve the desired results. 

== CI/CD and Jenkins
CI/CD are acronym's for contineous integration and contineous delivery/deployment used in DevOps. Contineous integration is a process where developers frequently merge code changes into a central repository and kick start code build, security scan and test execution using automation or manual methods. Contineous delivery/deployment is a process of application deployment into deployment destination.

Jenkins is an opensource automation server which helps to automate application code build, test and deployment. Jenkins comes with a vast variety of plugins which eases the various devops pipeline tool integrations into the build/deployment pipeline. In this blog, we will focus on how jenkins can be used as a piller of contineous integration and contineous deployment process for java based openliberty application deployment link:https://openliberty.io[OpenLiberty] 

== Getting ready
Below given is a generic architecture of a simple one dimensional devops pipeline (single environment view).

image::/img/blog/liberty-devops-generic-architecture.png[Liberty devops generic architecture diagram ,width=70%,align="center"]

In this blog i will give you a high level overview of using jenkins as a "Code build tool" and how it can be integrated with all other devops pipeline tools, detailed explanation are not in the scope of this blog. 

This blog explain the steps to deploy the application on Kubernetes, i am using IBM cloud kubernetes service for deployment, but same steps can be used to work with any other kubernetes service except connectivity commands to IBM cloud. 

=== Installing and configuring jenkins and additional tools ===

Install *jenkins* with all the recommended plugins link:https://www.jenkins.io/doc/book/installing/[install Jenkins], make sure that the following plugins are installed. You can install jenkins on any physical/virtual servers or it can be running as a container on Kubernetes itself.

* Maven
* Pipeline
* Multibranch Scan Webhook Trigger
* Docker
* Kubernetes

If you are using *Helm* to automate the application deployment, install it on the server where jenkins are installed. If you are running jenkins on container, do this installation on the base image used for creating jenkins image. If you are using any slave server to run the jenkins job, install helm on the slave server.

_A note about jenkins slave_

You are going to do the liberty java code build using jenkins pipeline scripts and you need to decide where you are going to run that script, either directly on jenkins master or you need the support of a good configuration server (or container ) for it. If your application is big, you will need the help of a slave to run it. 
More details about jenkins slave setup are provided at link:https://www.jenkins.io/doc/book/using/using-agents/[Jenkins slave setup], link:https://www.jenkins.io/doc/book/pipeline/syntax/[pipeline code details] 

*Additional tools*

Basic additional tools required on CI/CD pipeline apart from Jenkins are 

* A source code management (SCM) tool like GitHub.

     Provision a public or private github repository and checkin your code into it. 
     Create any branching strategy of your choice (example: develop --> qa --> develop branch hierarchy). 

* A credential store application like harshicorp vault (optional)

     Your credentials (like dockerhub credentials, artifactory api credentials, IKS api token, github personal access token etc) can be securely saved within Jenkins itself on the page link:http://localhost:8080/credentials/store/system/domain/_/newCredentials[Jenkins credentials page]. 
     Consider using external credential store application like vault for better security

* Maven repository and Docker image repository, like artifactory (optional)

     Create an IBM cloud image registry if required by following the steps in link:https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started[IBM Cloud Container Registry] for pushing the docker images created for deployment. 
     You can use public docker hub registry as well for this. 
     Artifactory is another popular software in the market for this link:https://www.jfrog.com/confluence/display/JFROG/Getting+Started+with+Artifactory+as+a+Docker+Registry[Artifactory as a Docker Registry]

* Vulnerability scanning tools, like Aqua, Trivy, NexusIQ, Sonarqube (optional)

      All the opensource jar files used in the code build and the application code itself need to be scanned before production deployed to make sure that its free of any critical vulnerabilities. 
      Sonarqube is the most popular tool used for static code analysis, you can do the basic scanning using the opensource version of this software link:https://www.sonarqube.org/downloads/[sonarqube server installation], link:https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/[sonarqube client setup on jenkins]
      Licenses software like sonatype nexusiq and aqua can be used for opensource jar scan and its remediation recommendantions link:https://support.aquasec.com/support/solutions/articles/16000112614-aqua-onboarding-guide[Aqua setup step], link:https://help.sonatype.com/iqserver/getting-started[NexusIQ setup steps].

* Kubernetes 

     Provision a kubernetes cluster on IBM cloud kubernetes service(IKS) , generate IKS API key for CLI connectivity, verify the basic k8s cluster login commands to various clusters or namespaces (like dev cluster, qa cluster etc).     
    
== Jenkins pipeline scripting introduction

It's recommended to adhere to the concept of infrastructure as a code (IaaC) in DevOps pipeline, pipeline scripting based jenkins jobs are a good example of this (you can use maven or freestyle jenkins jobs as well for the pipeline setup). You can use any 3 style of jenkins job setup shown below.

Writing pipeline code directly in Jenkins (need to take the backup of this jenkins instance to secure the code)

image::/img/blog/pipeline-code-on-jenkins.png[Pipeline code directly on Jenkins ,width=70%,align="center"]

Writing pipeline code on Jenkinsfile in git and mapping the same onto Jenkins

image::/img/blog/pipeline-code-on-git.png[Pipeline code on Git ,width=50%,align="center"]

Writing pipeline code on Jenkinsfile in git on different environments and mapping all the environment onto Jenkins

image::/img/blog/multiple-branch-pipeline-jenkinsview-with-corresponding-gitview.png[Multi branch pipeline setup and corresponding git view,width=60%,align="left"]

Only CLI commands can be used in pipeline code, on the other side, free style and maven type job have the advantage of UI based configuration.
Pipeline code syntax can be found at link:https://www.jenkins.io/doc/pipeline/tour/hello-world/[pipeline syntax]. On jenkins, use this page to generate pipeline code link:http://localhost:8080/job/pipeline_test/pipeline-syntax/[Jenkins] (sample page).

== Code build, packaging and Docker image

You are now ready for testing code build, packaging and generating docker image and push it to any remote docker repository. Remote docker repository is not required if your containerization application is providing the facility of local docker respository(like RedHat OpenShift )

A sample pipeline code for performing code build, packaging and generating docker image and pushing the same to remote docker repository is given below. You can use it by modifying the parameter section (<>)

 pipeline {
     agent any
     stages {
       stage('Build') {
           steps {
                checkout([$class: 'GitSCM', branches: [[name: '*/main']], extensions: [], userRemoteConfigs: [[credentialsId: ‘<git token>, url: 'https://github.com/liberty/app.git']]])
		configFileProvider([configFile('<settings_file.xml>’)]) {
                          sh '''
                                 mvn -U package
                                 docker login <remote-docker-image-repository-url> -u "${USERNAME}" -p “${PASSWORD}”
				  docker tag liberty-$<code identifier>:$<docker image version> <remote-docker-image-repository-url>/<docker-repo-name>/liberty-$<code identifier>:$<docker image version>
 				  docker push <remote-docker-image-repository-url>/<docker-repo-name>/liberty-$<code identifier>:$<docker image version>

                           '''   
                   }}}}}


Following are the parameter used in this example code

* git token: Generate the personal access token from github and paste the same at this location
* settings_file.xml: If you are using special proxy settings files to resolve the dependencies from any private maven repository, you can upload the same to config files page in jenkins and provide the same of the same at this location. Alternatively you can upload the settings file as secure credential files as well. Maven settings file can be generated from link:http://localhost:8080/configfiles/addConfig[generate maven settings file] or use turorials like link:https://www.baeldung.com/maven-settings-xml[generate maven settings file] to generate it
* remote-docker-image-repository-url : Docker image registry/repository url
* USERNAME/PASSWWORD: user name and password to connect to docker registry, this can be saved securely as jenkins cedentials and do the binding of the same to the pipeline job created.

image::/img/blog/jenkins-cred-binding-and-corresponding-param.png[Pipeline credential binding and corresponding param,width=30%,align="center"]

* code identifier: This is optional, a unique docker image identifier
* docker image version: docker image version number, a unique identifier

*important:* There are 2 ways to package the docker image, with or without embedding application code in the docker image. Downloading the code into container at runtime (in entrypoint file) will secure the application code if docker image repository is compromised.    

*security scan* Running automatic security scan of source code and dependency jars along with every code build is a good practice which can be implemented as part of CI/CD pipeline which ensures the security of the every version of deployed application. Static code analysis and opensource jar scan should be completed before proceeding to deployment. Use the steps explained in the tool setup stage to complete all security scans from jenkins on run time. Features like quality gate on sonarqube can be used to fail the code build in case of not satisfying the required code quality and coverage. Maven build command can be integrated with scan related CLI commands or these can be done on a different pipeline stage. Detailed steps to perform security scan will be available in another blog

== Deployment (CLI and Helm) 
Helm is a good option to facilitate the application deployment on the cloud platform, it eases deployment/maintenance steps and hence highly recommended. But we can do the application deployment on kubernetes using CLI commands directly from Jenkins shell or pipeline stages. 

=== CLI Deployment
When a Docker image is generated and saved on a repositories like K8s/OCP registry, IBM cloud remote registry, artifactory etc, then the docker deployment is very straightforward using kubernetes CLI commands. Either you can generate new image tag on every docker build and update this new name/tag on the deployment yaml file on GitHub (using git push) or you can depend on a single image name/tag for a particular feature release and change it to new on every subsequent release (This change can be done only on the current jenkins workspace file as well if not required to save the information on the github for reference purpose, also if multiple repositories are used for code and container configurations, this push method is helpful).  

As explained in the earlier section, after the kubernetes context is set to the required environment, run the kubectl commands to deploy and components like deployments, services, route, serviceaccount, secrets etc. The yaml files should be already available in the current Jenkins workspace downloaded as explained in the earlier stage (if code and container are part of same repository).   

link:https://kubernetes.io/docs/reference/kubectl/cheatsheet/[Kubernetes sample commands] 

=== Helm deployment
In this stage, we are ready to start the application deployment using Helm link:https://helm.sh/docs/helm/helm/[Helm]. Helm is already available from jenkins server (or on any attached jenkins slave - if we are using virtual machine as the slave, make sure helm is installed on that server and available for all users, if containerized slave are used, make sure the helm installation is done through the dockerfile of the attached image to the slave)

All the deployment related configirations, like, Pod, deployment, service should be completed and checked into github prior to appliction deployment trigger in the helm chart directory link:https://helm.sh/docs/helm/helm_create/[Helm create]

Run the "helm install" or "helm upgrade" from Jenkins shell or pipeline code to create the resources in the kubernetes cluster. Maintain all the helm resources in a separate folder in the git repository and make the modifications as per the requirement.

The name of the new docker image generated on the docker build can be updated on the helm file on run time (if you are adopting to this run time image name change strategy), you can use the "Git Push Plugin" for this purpose on Jenkins. 

Some helpful cli commands for using in Jenkins are given below

* ibmcloud plugin install container-service
* ibmcloud config --check-version=false
* ibmcloud ks cluster config --cluster <ibm cloud cluster id>
* helm uninstall <release name> -n <namespace>
* helm install <release name> . --namespace <namespace>

link:https://phoenixnap.com/kb/helm-commands-cheat-sheet[Helm commands]

Use the kubectl commands to  check the status of deployment or go to the kubernetes dashboard and check the status of the deployment

image::/img/blog/K8S-dashboard.png[Kubernetes dashboard example ,width=70%,align="center"]

== QA testing options
Apart from running JUnit test cases along with the code build phase, we can configure jenkins and deployment configurations to trigger the funtional/integration QA test cases automatically after the deployment in each environment. 

Configure the test cases on jenkins job and test it manually. Create an "Authentication Token" in "Trigger builds remotely" section under "Build Triggers". Trigger this test case from docker "entrypoint" file using remote rest api call using this authentication token as the identifier

Eg: curl -I -u <auth-token> https://<jenkins-host>/job/<job-name>/build?token=<authentication-token>
Note: Auth token can be generated from postman

== Kubernetes monitoring tools
Several enterprise and open source options are available in market for kubernetes cluster resource monitoring and log monitoring. Some working example resources are given below. 

* OpenSource :

    -> https://grafana.com/oss/loki/
    -> https://medium.com/nerd-for-tech/logging-at-scale-in-kubernetes-using-grafana-loki-3bb2eb0c0872
    -> https://prometheus.io
    -> https://k21academy.com/docker-kubernetes/prometheus-grafana-monitoring/

* Enterprise :

    -> https://www.splunk.com/en_us/blog/platform/deploy-splunk-enterprise-on-kubernetes-splunk-connect-for-kubernetes-and-splunk-insights-for-containers-beta-part-1.html
    -> https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-container-platforms/kubernetes


