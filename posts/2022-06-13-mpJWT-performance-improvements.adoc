---
layout: post
title: "How we doubled throughput when securing microservices with JWT on Open LIberty"
# Do NOT change the categories section
categories: blog
author_picture: https://avatars3.githubusercontent.com/jdmcclur
author_github: https://github.com/jdmcclur
seo-title: How we doubled throughput when securing microservices with JWT on Open LIberty - OpenLiberty.io
seo-description: Details of the many changes made in Open Liberty over the last few releases (22.0.0.2 to 22.0.0.6) to double mpJWT processing throughput.
blog_description: "Details of the many changes made in Open Liberty over the last few releases (22.0.0.2 to 22.0.0.6) to double mpJWT processing throughput."
open-graph-image: https://openliberty.io/img/twitter_card.jpg
---
= How we doubled throughput when securing microservices with JWT on Open LIberty
Joe McClure <https://github.com/jdmcclur>
:imagesdir: /
:url-prefix:
:url-about: /
//Blank line here is necessary before starting the body of the post.

The performance throughput of Open Liberty for applicaions secured using MicroProfile 5.0 JWT has almost doubled in 22.0.0.6 when compared with 22.0.0.2, in a simple scenario. In this blog post I will discuss how we made these performance improvements.

[.img_border_light]
image::/img/blog/mpjwt-prim-chart-1.png[Microprofile JWT Performance Chart 1,width=70%,align="center"]

To test this, I wrote a simple primitive application. It has a RESTful endpoint that requires a JWT with one of the groups as “user”. If a client accesses the endpoint (/access/test) with a valid JWT in the Authorization Header, the application then looks at the injected token for any groups and returns the subject to the client.

[source,java]
----
@Path("/access")
public class JWTProtected {

  @Inject private JsonWebToken jwt;
  
  @GET
  @RolesAllowed("user")
  @Path("/test")
  public Response test() {
    
    Set<String> groups = jwt.getGroups();
    if (!groups.contains("user")) {
      System.out.println("Error");
    }
    
    String subject = jwt.getSubject();
    return Response.ok(subject).build();
  }
}
----

Example call to the endpoint with curl (JWTs are long):
[source,bash]
----
curl -H "Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJodHRwOi8vYWNtZWFpci1tcyIsImV4cCI6MTY1NDIwMzk1NCwianRpIjoianRpIiwiaWF0IjoxNjU0MjAwMzU0LCJzdWIiOiJzdWJqZWN0IiwidXBuIjoic3ViamVjdCIsImdyb3VwcyI6WyJ1c2VyIl19.oiXaGhslxd_hGuCfBiXe3fdpfH4udcpCB-meMBw8bKYHFvYXuMmvuV6Jy98F53D5L3uwy9aeysstAfTIVIKpkMmWFdH2e9K93qRfiZnM4nR9uzMW7UGK2QClKvZGSLOUZeGSjyREGcMW9DQqG5mnRLDXTXc27IRfeEMhjxsQ90lwPMSAUZXQaZ14MBHnT-lftajdVo3B3FHlW7V4Bf5BBWgExNEMmfP880ba3tkKgl_mEB8Y6TRJXmLOleDM5cv_d-bsSCk1mzs3KyCLQZV5X-pq-XDgTL7m0DRV7o--AYEb-qC4S_asf7O5WngbOAK7T9DIeL2HFXXGQADcRR718w" http://localhost:9080/access/test
----

I used link:{https://jmeter.apache.org/}[Apache JMeter] to apply a load with 100 clients. Each client generates a JWT, uses it around 20 times to access the endpoint, then generates a new JWT. 

So, how did we double throughput performance? It involved many changes, some big and some small. The first thing we noticed in a sampling profile was a lot of time spent (8.53%) doing a toString on the Subject. (Below is simplified output of our profiling tools)

[source]
----
8.53 com/ibm/ws/webcontainer/security/WebAppSecurityCollaboratorImpl$4.run()Ljava/lang/String;
  8.53 javax/security/auth/Subject.toString()Ljava/lang/String;
----

After reviewing the code, we discovered the toString() is only needed when validation is enabled, which is not the normal use case. 

link:{https://github.com/jhanders34}[Jared Anderson] fixed this with the following PR: https://github.com/OpenLiberty/open-liberty/pull/20334

This change improved throughput 12.5% in 22.0.0.4.
[.img_border_light]
image::img/blog/mpjwt-prim-chart-2.png[Microprofile JWT Performance Chart 2 ,width=70%,align="center"]

Next, we noticed we were spending a lot of time parsing the JSON of the JWT (7.42%), and parsing the same JSON multiple times. 

[source]
----
1.51 org/jose4j/jwt/JwtClaims.<init>(Ljava/lang/String;Lorg/jose4j/jwt/consumer/JwtContext;)
1.64 com/ibm/ws/security/mp/jwt/impl/utils/ClaimsUtils.parsePayloadAndCreateClaims(Ljava/lang/String;)
1.93 org/jose4j/jwx/Headers.setEncodedHeader(Ljava/lang/String;)
2.34 com/ibm/ws/security/common/jwk/utils/JsonUtils.claimsFromJsonObject(Ljava/lang/String;)
  7.42 org/jose4j/json/JsonUtil.parseJson(Ljava/lang/String;)Ljava/util/Map;
 
----

Jared made this more efficient, and changed a few other related areas with the following PRs: +
https://github.com/OpenLiberty/open-liberty/pull/20700 +
https://github.com/OpenLiberty/open-liberty/pull/20723 +
https://github.com/OpenLiberty/open-liberty/pull/20963 

I made a small change to only compile regular expressions once instead of every time the code is invoked. I also changed a stream api to be a more efficient for loop.

https://github.com/OpenLiberty/open-liberty/pull/20753 +
https://github.com/OpenLiberty/open-liberty/pull/20739 

With these changes, Open Liberty was now 32% faster in 22.0.0.5 than 22.0.0.2.

[.img_border_light]
image::img/blog/mpjwt-prim-chart-3.png[Microprofile JWT Performance Chart 3 ,width=70%,align="center"]

Finally, the biggest change was when we discovered that our JWT Cache could perform much better. We were validating the JWT on every request, even if it had already been processed before. 

[source]
----
32.27 com/ibm/ws/security/jwt/internal/ConsumerUtil.getSigningKeyAndParseJwtWithValidation(Ljava/lang/String;Lcom/ibm/ws/security/jwt/config/JwtConsumerConfig;Lorg/jose4j/jwt/consumer/JwtContext;)
 
  32.27 com/ibm/ws/security/jwt/internal/ConsumerUtil.parseJwtWithValidation(Ljava/lang/String;Lorg/jose4j/jwt/consumer/JwtContext;Lcom/ibm/ws/security/jwt/config/JwtConsumerConfig;Ljava/security/Key;)
----

link:{https://github.com/ayoho}[Adam Yoho] was able to fix this with: 
https://github.com/OpenLiberty/open-liberty/pull/20733 

Jared also made an additional change to improve the efficiency of regular expressions: https://github.com/OpenLiberty/open-liberty/pull/20922

With these final two changes, throughput is now 97.8% better than in 22.0.0.2!

[.img_border_light]
image::img/blog/mpjwt-prim-chart-6.png[Microprofile JWT Performance Chart 4 ,width=70%,align="center"]

These results are with a very simple primitive, which probably won't resemble a real world application. How much does throughput improve in a more normal application? With link:{https://github.com/blueperf/acmeair-mainservice-java}[AcmeAirMS], which has two services that consume JWTs (booking and customer), performance improved 17.5% - still impressive.

[.img_border_light]
image::img/blog/mpjwt-acmeairms-chart.png[Microprofile JWT Performance Chart 5 ,width=70%,align="center"]

In summary, we made many changes over the last few releases to improve the throupghput performance of processing and Microprofile JWTs by almost double.

